# Toxic_comments_detection_engine

Данный проект является итоговой аттестационной работой в рамках профессиональной переподготовки по курсу «Python-разработчик» и содержит сквозное описание полного цикла от определения проблемы с точки зрения продукта до получения готовой модели машинного обучения, проверки качества предсказаний на основе модели, оптимизацией гиперпараметров модели в целях повышения качества предсказаний, а также исследования возможных путей горизонтального развития полученного технологического решения.

1. Проработка бизнес-задачи проекта (проблематика проекта)

Предположим, мы трудимся в некоторой компании, пользователи интернет-сервиса которой пишут много комментариев (социальная сеть, форум, Youtube-канал). В определенный момент начали появляться много негативных комментариев, и от product-менеджера у нас поступила задача разработать систему, которая будет определять, фильтровать и/или блокировать определённые комментарии, в которых присутствует ненормативная лексика, нецензурные выражения, брань, агрессия и тому подобное. На данном этапе введём обобщающее 	 понятие «токсичный комментарий» с отсылкой к вышеперечисленному.

Перейдём об бизнеса к задаче машинного обучения. Итак, введя понятие токсичный комментарий мы также имеем обратное понятие, которое можно сформулировать как «обычный, нейтральный, положительный». Следовательно задача сводится к следующему типу: разработать бинарный классификатор, который на вход будет получать текстовый комментарий, а на выходе будет выдавать два класса (0 — обычный, 1 — токсичный).

Необходимо максимизировать количество удалённых негативных комментариев, но при этом случайно не удалить позитивные и нейтральные комментарии, чтобы пользователи интернет-сервиса не заявили о «необоснованный цензуре» и удалённых сообщениях, оставленных ими лично и не нарушающих правил публикации на сервисе. Для этого введём ограничение на применение разрабатываемой ML-системы фильтрации, что только в одном из 20-ти случаев система имеет право ошибиться и случайно удалить обычный комментарий (не токсичный). 
Чтобы задать условие задачи, вычислим вероятность верного предсказания необходимого нам признака { 100-(100/20)=95 } и получим значение 95%.

Формализуем поставленную задачу через метрики:
Необходимо максимизировать recall (найденные негативные комментарии) при сохранении условия precision > 0,95 (точность предсказания признака токсичного комментария).


2. Понимание данных, составление датасета

Из-за отсутствия реального набора данных с интернет-сервиса гипотетической бизнес-компании, был осуществлён поиск большого датасета, размеченного заранее на токсичные и нетоксичные записи. В результате поиска данные взяты с сайта Kaggle.com. Как гласит описание: датасет собран из двух сервисов 2ch.hk и pikabu.ru (14412 записей).



